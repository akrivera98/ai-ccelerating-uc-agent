experiment_name: "full_pipeline"

seed: 42

device: cpu

backend: torch

solver: DIFFCP

dataset:
  data_dir: "data/Train_Data"
  ed_instance_path: "data/Train_Data/instance_2021_Q1_1/InputData.json"

splits:
  train: 1.0
  val: 0.0
  test: 0.0

model:
  name: "TwoHeadMLP"
  hyper_params:
    input_size: 318
    hidden_size: 128
    num_hidden_layers: 3
    final_activation: "sigmoid"   # or "relu" / "none"

rounding_at_training: "STE"

training:
  batch_size: 16
  criterion: "CustomLoss"        
  optimizer: "Adam"           
  learning_rate: 0.001
  num_epochs: 5
  val_every: 0
